{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/behnambaloochy/spaceship-titanic?scriptVersionId=144132350\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\n# from sklearn.preprocessing import StandardScaler\n# from sklearn.model_selection import train_test_split\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.decomposition import PCA\n# from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\nfrom sklearn.pipeline import make_pipeline\nfrom sklearn.model_selection import cross_validate\n\n\n# Data Preprocessing ----------------------------------------------------------------------------------\n# df_train = pd.read_csv('train.csv', encoding='utf-8')\ndf_train = pd.read_csv('/kaggle/input/spaceship-titanic/train.csv', encoding='utf-8')\n\n# print('train has {} rows and {} columns'.format(*df_train.shape))\n# df_train.info()\n# df_train[['VIP', 'CryoSleep', 'FoodCourt', 'ShoppingMall', 'Spa', 'VRDeck']] = \\\n# df_train[['VIP', 'CryoSleep', 'FoodCourt', 'ShoppingMall', 'Spa', 'VRDeck']].fillna(value=0)\n# df_train = df_train.dropna(how=\"any\")\n\n# df_test = pd.read_csv('test.csv', encoding='utf-8')\ndf_test = pd.read_csv('/kaggle/input/spaceship-titanic/test.csv', encoding='utf-8')\n\n# df_test.info()\n# print('test has {} rows and {} columns'.format(*df_test.shape))\n# df_test[\"CryoSleep\"] = df_test[\"CryoSleep\"].fillna(df_test[\"CryoSleep\"].mean())\n\n\n# df_test = df_test.fillna(0)\n# print(df_train.head(10))\n# print(df_test.head(10))\n\ndf_train[\"Transported\"] = df_train[\"Transported\"].astype(int)\n# y_train = df_train[['Transported']].values\ny_train = df_train.iloc[:, 13].values\n\n# df_train['VIP'] = df_train['VIP'].astype(int)\n# df_train['CryoSleep'] = df_train['CryoSleep'].astype(int)\nX_train = df_train.iloc[:, [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]].values\n\n# Categorical Feature Encoding**********\n# print('HomePlanet values: ', df_test[\"HomePlanet\"].unique())\n# options_HomePlanet = {label: idx for idx, label in enumerate(np.unique(df_train['HomePlanet']))}\noptions_HomePlanet = {}\nfor i in range(0, df_train[\"HomePlanet\"].unique().shape[0]):\n    options_HomePlanet[df_train[\"HomePlanet\"].unique()[i]] = i+1\n# df_train[\"HomePlanet\"] = df_train[\"HomePlanet\"].map(options_HomePlanet)\nj = 0\nfor i in X_train[:,0]:\n    X_train[j,0] = options_HomePlanet.get(i)\n    j += 1\n\n# print('Train Cabin values: ', df_train[3].unique())\n# print('Test Cabin values: ', df_test[\"Cabin\"].unique())\noptions_Cabin = {}\nfor i in range(0, df_train[\"Cabin\"].unique().shape[0]):\n    options_Cabin[df_train[\"Cabin\"].unique()[i]] = i+1\nj = 0\nfor i in X_train[:,2]:\n    X_train[j,2] = options_Cabin.get(i)\n    j += 1\n\n# print('Destination values: ', df_test[\"Destination\"].unique())\noptions_Destination = {}\nfor i in range(0, df_train[\"Destination\"].unique().shape[0]):\n    options_Destination[df_train[\"Destination\"].unique()[i]] = i+1\nj = 0\nfor i in X_train[:,3]:\n    X_train[j,3] = options_Destination.get(i)\n    j += 1\n# **********\n\nX_train[:,1] = np.where(X_train[:,1] == 'True', 1, 0)\nX_train[:,5] = np.where(X_train[:,5] == 'True', 1, 0)\nX_train = np.float_(X_train)\n# print('Class labels:', np.unique(y_train))\n# imr = imr.fit(X_train)\n# X_train = imr.transform(X_train)\n\n# df_test['VIP'] = df_test['VIP'].astype(int)\n# df_test['CryoSleep'] = df_test['CryoSleep'].astype(int)\nX_test = df_test.iloc[:, [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]].values\n\n# Categorical Feature Encoding**********\nj = 0\nfor i in X_test[:,0]:\n    X_test[j,0] = options_HomePlanet.get(i)\n    j += 1\n\nj = 0\nfor i in X_test[:,2]:\n    X_test[j,2] = options_Cabin.get(i)\n    j += 1\n\nj = 0\nfor i in X_test[:,3]:\n    X_test[j,3] = options_Destination.get(i)\n    j += 1\n# **********\n\nX_test[:,1] = np.where(X_test[:,1] == 'True', 1, 0)\nX_test[:,5] = np.where(X_test[:,5] == 'True', 1, 0)\nX_test = np.float_(X_test)\n\n# imr = imr.fit(X_test)\n# X_test = imr.transform(X_test)\n\n# X_train, X_valid, y_train, y_valid = train_test_split(X_train, y_train, test_size=0.3, random_state=1, stratify=y_train)\n\n# Feature Scaling---------------------------------------------------------------------------------------\n# sc = StandardScaler()\n# sc.fit(X_train)\n# X_train_std = sc.transform(X_train)\n# X_test_std = sc.transform(X_test)\n\n\"\"\"\n# K-fold cross validation-------------------------------------------------------------------------------\ns_i = SimpleImputer(missing_values=np.nan, strategy=\"mean\")\nX_train_SI = s_i.fit_transform(X_train)\npca = PCA(n_components=10)\nX_train_PCA = pca.fit_transform(X_train_SI)\n\nhyperparameter_score_list = []\nfor n_est in range(1,51):\n    rfc = RandomForestClassifier(n_estimators=n_est, random_state=1, n_jobs=2)\n    scores = cross_validate(rfc, X_train_PCA, y_train, cv=10, scoring='accuracy')\n    mean_score = np.mean(scores['test_score'])\n    hyperparameter_score_list.append([n_est, mean_score])\nprint(hyperparameter_score_list)\n\"\"\"\n\n# Define Data Pipeline----------------------------------------------------------------------------------\npipe_rf = make_pipeline(SimpleImputer(missing_values=np.nan, strategy=\"mean\"), \n                        PCA(n_components=10), \n                        RandomForestClassifier(n_estimators=25, random_state=1, n_jobs=2))\n\n# sklearn-Random Forest Training------------------------------------------------------------------------\n# forest = RandomForestClassifier(n_estimators=25, random_state=1, n_jobs=2)\n# forest.fit(X_train, y_train)\npipe_rf.fit(X_train, y_train)\n# sklearn-Random Forest Prediction----------------------------------------------------------------------\ny_pred = pipe_rf.predict(X_test)\n\n# Submission--------------------------------------------------------------------------------------------\ntrans = []\nfor i in y_pred:\n    trans.append(i==1)\nsubmission = np.column_stack((df_test.PassengerId, trans))\nprint(submission)\nprint(np.shape(submission))\ndf_result = pd.DataFrame(submission)\ndf_result.to_csv(\"/kaggle/working/submission.csv\", header=['PassengerId', 'Transported'], index=False)\n# df_result.to_csv(\"submission.csv\", header=['PassengerId', 'Transported'], index=False)\n# feature_names = ['CryoSleep', 'Age', 'VIP', 'RoomService', 'FoodCourt', 'Shopping', 'Spa', 'VRDeck']\n","metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.status.busy":"2023-09-25T05:19:13.561548Z","iopub.execute_input":"2023-09-25T05:19:13.561905Z","iopub.status.idle":"2023-09-25T05:19:21.574227Z","shell.execute_reply.started":"2023-09-25T05:19:13.561876Z","shell.execute_reply":"2023-09-25T05:19:21.573303Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Learning Curve","metadata":{}},{"cell_type":"code","source":"print('Number of class 0 examples:', X_train[y_train == 0].shape[0])\nprint('Number of class 1 examples:', X_train[y_train == 1].shape[0])\nprint('The classes are balanced.')","metadata":{"execution":{"iopub.status.busy":"2023-09-25T05:19:59.546967Z","iopub.execute_input":"2023-09-25T05:19:59.547335Z","iopub.status.idle":"2023-09-25T05:19:59.554284Z","shell.execute_reply.started":"2023-09-25T05:19:59.54729Z","shell.execute_reply":"2023-09-25T05:19:59.553301Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nfrom sklearn.model_selection import learning_curve\n\ntrain_sizes, train_scores, test_scores = learning_curve(estimator=pipe_rf, X=X_train, y=y_train,\n                                         train_sizes=np.linspace(0.1, 1.0, 10), cv=10, n_jobs=1)\n\n\ntrain_mean = np.mean(train_scores, axis=1)\ntrain_std = np.std(train_scores, axis=1)\ntest_mean = np.mean(test_scores, axis=1)\ntest_std = np.std(test_scores, axis=1)\n\nplt.plot(train_sizes, train_mean,\n         color='blue', marker='o',\n         markersize=5, label='Training accuracy')\n\nplt.fill_between(train_sizes,\n                 train_mean + train_std,\n                 train_mean - train_std,\n                 alpha=0.15, color='blue')\n\nplt.plot(train_sizes, test_mean,\n         color='green', linestyle='--',\n         marker='s', markersize=5,\n         label='Validation accuracy')\n\nplt.fill_between(train_sizes,\n                 test_mean + test_std,\n                 test_mean - test_std,\n                 alpha=0.15, color='green')\n\nplt.grid()\nplt.xlabel('Number of training examples')\nplt.ylabel('Accuracy')\nplt.legend(loc='lower right')\n# plt.ylim([0.8, 1.03])\nplt.tight_layout()\nplt.autoscale()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-09-18T10:29:18.268579Z","iopub.execute_input":"2023-09-18T10:29:18.268996Z","iopub.status.idle":"2023-09-18T10:29:51.482453Z","shell.execute_reply.started":"2023-09-18T10:29:18.268964Z","shell.execute_reply":"2023-09-18T10:29:51.481538Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Validation Curve","metadata":{}},{"cell_type":"code","source":"pipe_rf.get_params(deep=True)","metadata":{"execution":{"iopub.status.busy":"2023-09-18T10:28:24.946548Z","iopub.execute_input":"2023-09-18T10:28:24.946955Z","iopub.status.idle":"2023-09-18T10:28:24.963158Z","shell.execute_reply.started":"2023-09-18T10:28:24.946928Z","shell.execute_reply":"2023-09-18T10:28:24.962074Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import validation_curve\nparam_range = [i for i in range(1, 40)]\ntrain_scores, test_scores = validation_curve(\n                            estimator=pipe_rf, \n                            X=X_train, \n                            y=y_train,\n                            param_name='randomforestclassifier__n_estimators', \n                            param_range=param_range,\n                            cv=10)\n\ntrain_mean = np.mean(train_scores, axis=1)\ntrain_std = np.std(train_scores, axis=1)\ntest_mean = np.mean(test_scores, axis=1)\ntest_std = np.std(test_scores, axis=1)\n\nplt.plot(param_range, train_mean, \n         color='blue', marker='o', \n         markersize=5, label='Training accuracy')\n\nplt.fill_between(param_range, train_mean + train_std,\n                 train_mean - train_std, alpha=0.15,\n                 color='blue')\n\nplt.plot(param_range, test_mean, \n         color='green', linestyle='--', \n         marker='s', markersize=5, \n         label='Validation accuracy')\n\nplt.fill_between(param_range, \n                 test_mean + test_std,\n                 test_mean - test_std, \n                 alpha=0.15, color='green')\n\nplt.grid()\n# plt.xscale('log')\nplt.legend(loc='lower right')\nplt.xlabel('Parameter n_estimators')\nplt.ylabel('Accuracy')\n# plt.ylim([0.6, 1.0])\n# plt.xlim([0, 51])\nplt.tight_layout()\nplt.autoscale()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-09-18T10:30:00.981145Z","iopub.execute_input":"2023-09-18T10:30:00.981494Z","iopub.status.idle":"2023-09-18T10:32:52.758477Z","shell.execute_reply.started":"2023-09-18T10:30:00.981466Z","shell.execute_reply":"2023-09-18T10:32:52.75759Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Grid Search","metadata":{}},{"cell_type":"code","source":"from sklearn.model_selection import GridSearchCV\nfrom sklearn.svm import SVC\nfrom sklearn.preprocessing import StandardScaler\n\npipe_svc = make_pipeline(SimpleImputer(missing_values=np.nan, strategy=\"mean\") ,StandardScaler(), SVC(random_state=1))\nparam_range = [0.0001, 0.001, 0.01, 0.1, 1.0, 10.0, 100.0, 1000.0]\n\nparam_grid = [{'svc__C': param_range, \n               'svc__kernel': ['linear']},\n              {'svc__C': param_range, \n               'svc__gamma': param_range, \n               'svc__kernel': ['rbf']}]\n\ngs = GridSearchCV(estimator=pipe_svc, \n                  param_grid=param_grid, \n                  scoring='accuracy', \n                  refit=True,\n                  cv=10,\n                  n_jobs=-1)\n\ngs = gs.fit(X_train, y_train)\nprint(gs.best_score_)\nprint(gs.best_params_)\nclf = gs.best_estimator_\n# clf.fit(X_train, y_train) \n# note that we do not need to refit the classifier\n# because this is done automatically via refit=True.\nprint(f'Test accuracy: {clf.score(X_test, y_test):.3f}')","metadata":{"execution":{"iopub.status.busy":"2023-09-18T10:34:42.315104Z","iopub.execute_input":"2023-09-18T10:34:42.315466Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Randomized Search","metadata":{}},{"cell_type":"code","source":"from sklearn.model_selection import RandomizedSearchCV\nfrom sklearn.svm import SVC\nfrom sklearn.preprocessing import StandardScaler\nimport scipy.stats\n\npipe_svc = make_pipeline(SimpleImputer(missing_values=np.nan, strategy=\"mean\") ,StandardScaler(), SVC(random_state=1))\nparam_range = scipy.stats.loguniform(0.0001, 1000.0)\n\nparam_grid = [{'svc__C': param_range, \n               'svc__kernel': ['linear']},\n              {'svc__C': param_range, \n               'svc__gamma': param_range, \n               'svc__kernel': ['rbf']}]\n\nrs = RandomizedSearchCV(estimator=pipe_svc,\n                        param_distributions=param_grid,\n                        scoring='accuracy',\n                        refit=True,\n                        n_iter=20,\n                        cv=10,\n                        random_state=1,\n                        n_jobs=-1)\n\nrs = rs.fit(X_train, y_train)\nprint(rs.best_score_)\nprint(rs.best_params_)","metadata":{},"execution_count":null,"outputs":[]}]}