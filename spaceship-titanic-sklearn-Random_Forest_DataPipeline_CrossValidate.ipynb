{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/behnambaloochy/spaceship-titanic?scriptVersionId=143375092\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\n# from sklearn.preprocessing import StandardScaler\n# from sklearn.model_selection import train_test_split\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.decomposition import PCA\n# from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\nfrom sklearn.pipeline import make_pipeline\nfrom sklearn.model_selection import cross_validate\n\n\n# Data Preprocessing ----------------------------------------------------------------------------------\ndf_train = pd.read_csv('/kaggle/input/spaceship-titanic/train.csv', encoding='utf-8')\n# print('train has {} rows and {} columns'.format(*df_train.shape))\n# df_train.info()\n# df_train[['VIP', 'CryoSleep', 'FoodCourt', 'ShoppingMall', 'Spa', 'VRDeck']] = \\\n# df_train[['VIP', 'CryoSleep', 'FoodCourt', 'ShoppingMall', 'Spa', 'VRDeck']].fillna(value=0)\n# df_train = df_train.dropna(how=\"any\")\n\ndf_test = pd.read_csv('/kaggle/input/spaceship-titanic/test.csv', encoding='utf-8')\n# df_test.info()\n# print('test has {} rows and {} columns'.format(*df_test.shape))\n# df_test[\"CryoSleep\"] = df_test[\"CryoSleep\"].fillna(df_test[\"CryoSleep\"].mean())\n\n\n# df_test = df_test.fillna(0)\n# print(df_train.head(10))\n# print(df_test.head(10))\n\ndf_train[\"Transported\"] = df_train[\"Transported\"].astype(int)\n# y_train = df_train[['Transported']].values\ny_train = df_train.iloc[:, 13].values\n\n# df_train['VIP'] = df_train['VIP'].astype(int)\n# df_train['CryoSleep'] = df_train['CryoSleep'].astype(int)\nX_train = df_train.iloc[:, [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]].values\n\n# Categorical Feature Encoding**********\n# print('HomePlanet values: ', df_test[\"HomePlanet\"].unique())\n# options_HomePlanet = {label: idx for idx, label in enumerate(np.unique(df_train['HomePlanet']))}\noptions_HomePlanet = {}\nfor i in range(0, df_train[\"HomePlanet\"].unique().shape[0]):\n    options_HomePlanet[df_train[\"HomePlanet\"].unique()[i]] = i+1\n# df_train[\"HomePlanet\"] = df_train[\"HomePlanet\"].map(options_HomePlanet)\nj = 0\nfor i in X_train[:,0]:\n    X_train[j,0] = options_HomePlanet.get(i)\n    j += 1\n\n# print('Train Cabin values: ', df_train[3].unique())\n# print('Test Cabin values: ', df_test[\"Cabin\"].unique())\noptions_Cabin = {}\nfor i in range(0, df_train[\"Cabin\"].unique().shape[0]):\n    options_Cabin[df_train[\"Cabin\"].unique()[i]] = i+1\nj = 0\nfor i in X_train[:,2]:\n    X_train[j,2] = options_Cabin.get(i)\n    j += 1\n\n# print('Destination values: ', df_test[\"Destination\"].unique())\noptions_Destination = {}\nfor i in range(0, df_train[\"Destination\"].unique().shape[0]):\n    options_Destination[df_train[\"Destination\"].unique()[i]] = i+1\nj = 0\nfor i in X_train[:,3]:\n    X_train[j,3] = options_Destination.get(i)\n    j += 1\n# **********\n\nX_train[:,1] = np.where(X_train[:,1] == 'True', 1, 0)\nX_train[:,5] = np.where(X_train[:,5] == 'True', 1, 0)\nX_train = np.float_(X_train)\n# print('Class labels:', np.unique(y_train))\n# imr = imr.fit(X_train)\n# X_train = imr.transform(X_train)\n\n# df_test['VIP'] = df_test['VIP'].astype(int)\n# df_test['CryoSleep'] = df_test['CryoSleep'].astype(int)\nX_test = df_test.iloc[:, [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]].values\n\n# Categorical Feature Encoding**********\nj = 0\nfor i in X_test[:,0]:\n    X_test[j,0] = options_HomePlanet.get(i)\n    j += 1\n\nj = 0\nfor i in X_test[:,2]:\n    X_test[j,2] = options_Cabin.get(i)\n    j += 1\n\nj = 0\nfor i in X_test[:,3]:\n    X_test[j,3] = options_Destination.get(i)\n    j += 1\n# **********\n\nX_test[:,1] = np.where(X_test[:,1] == 'True', 1, 0)\nX_test[:,5] = np.where(X_test[:,5] == 'True', 1, 0)\nX_test = np.float_(X_test)\n\n# imr = imr.fit(X_test)\n# X_test = imr.transform(X_test)\n\n# X_train, X_valid, y_train, y_valid = train_test_split(X_train, y_train, test_size=0.3, random_state=1, stratify=y_train)\n\n# Feature Scaling---------------------------------------------------------------------------------------\n# sc = StandardScaler()\n# sc.fit(X_train)\n# X_train_std = sc.transform(X_train)\n# X_test_std = sc.transform(X_test)\n\n\"\"\"\n# K-fold cross validation-------------------------------------------------------------------------------\ns_i = SimpleImputer(missing_values=np.nan, strategy=\"mean\")\nX_train_SI = s_i.fit_transform(X_train)\npca = PCA(n_components=10)\nX_train_PCA = pca.fit_transform(X_train_SI)\n\nhyperparameter_score_list = []\nfor n_est in range(1,51):\n    rfc = RandomForestClassifier(n_estimators=n_est, random_state=1, n_jobs=2)\n    scores = cross_validate(rfc, X_train_PCA, y_train, cv=10, scoring='accuracy')\n    mean_score = np.mean(scores['test_score'])\n    hyperparameter_score_list.append([n_est, mean_score])\nprint(hyperparameter_score_list)\n\"\"\"\n\n# Define Data Pipeline----------------------------------------------------------------------------------\npipe_rf = make_pipeline(SimpleImputer(missing_values=np.nan, strategy=\"mean\"), \n                        PCA(n_components=10), \n                        RandomForestClassifier(n_estimators=25, random_state=1, n_jobs=2))\n\n# sklearn-Random Forest Training------------------------------------------------------------------------\n# forest = RandomForestClassifier(n_estimators=25, random_state=1, n_jobs=2)\n# forest.fit(X_train, y_train)\npipe_rf.fit(X_train, y_train)\n# sklearn-Random Forest Prediction----------------------------------------------------------------------\ny_pred = pipe_rf.predict(X_test)\n\n# Submission--------------------------------------------------------------------------------------------\ntrans = []\nfor i in y_pred:\n    trans.append(i==1)\nsubmission = np.column_stack((df_test.PassengerId, trans))\nprint(submission)\nprint(np.shape(submission))\ndf_result = pd.DataFrame(submission)\ndf_result.to_csv(\"/kaggle/working/submission.csv\", header=['PassengerId', 'Transported'], index=False)\n\n# feature_names = ['CryoSleep', 'Age', 'VIP', 'RoomService', 'FoodCourt', 'Shopping', 'Spa', 'VRDeck']\n","metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.status.busy":"2023-09-18T07:12:41.622659Z","iopub.execute_input":"2023-09-18T07:12:41.623055Z","iopub.status.idle":"2023-09-18T07:12:50.525703Z","shell.execute_reply.started":"2023-09-18T07:12:41.623022Z","shell.execute_reply":"2023-09-18T07:12:50.52431Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Learning Curve","metadata":{}},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nfrom sklearn.model_selection import learning_curve\n\ntrain_sizes, train_scores, test_scores = learning_curve(estimator=pipe_rf, X=X_train, y=y_train,\n                                         train_sizes=np.linspace(0.1, 1.0, 10), cv=10, n_jobs=1)\n\n\ntrain_mean = np.mean(train_scores, axis=1)\ntrain_std = np.std(train_scores, axis=1)\ntest_mean = np.mean(test_scores, axis=1)\ntest_std = np.std(test_scores, axis=1)\n\nplt.plot(train_sizes, train_mean,\n         color='blue', marker='o',\n         markersize=5, label='Training accuracy')\n\nplt.fill_between(train_sizes,\n                 train_mean + train_std,\n                 train_mean - train_std,\n                 alpha=0.15, color='blue')\n\nplt.plot(train_sizes, test_mean,\n         color='green', linestyle='--',\n         marker='s', markersize=5,\n         label='Validation accuracy')\n\nplt.fill_between(train_sizes,\n                 test_mean + test_std,\n                 test_mean - test_std,\n                 alpha=0.15, color='green')\n\nplt.grid()\nplt.xlabel('Number of training examples')\nplt.ylabel('Accuracy')\nplt.legend(loc='lower right')\n# plt.ylim([0.8, 1.03])\nplt.tight_layout()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-09-18T07:33:59.497598Z","iopub.execute_input":"2023-09-18T07:33:59.497989Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Validation Curve","metadata":{}},{"cell_type":"code","source":"pipe_rf.get_params(deep=True)","metadata":{"execution":{"iopub.status.busy":"2023-09-18T07:30:34.8277Z","iopub.execute_input":"2023-09-18T07:30:34.828095Z","iopub.status.idle":"2023-09-18T07:30:34.840783Z","shell.execute_reply.started":"2023-09-18T07:30:34.828065Z","shell.execute_reply":"2023-09-18T07:30:34.839541Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import validation_curve\nparam_range = np.linspace(1, 50)\ntrain_scores, test_scores = validation_curve(\n                            estimator=pipe_rf, \n                            X=X_train, \n                            y=y_train,\n                            param_name='randomforestclassifier__n_estimators', \n                            param_range=param_range,\n                            cv=10)\n\ntrain_mean = np.mean(train_scores, axis=1)\ntrain_std = np.std(train_scores, axis=1)\ntest_mean = np.mean(test_scores, axis=1)\ntest_std = np.std(test_scores, axis=1)\n\nplt.plot(param_range, train_mean, \n         color='blue', marker='o', \n         markersize=5, label='Training accuracy')\n\nplt.fill_between(param_range, train_mean + train_std,\n                 train_mean - train_std, alpha=0.15,\n                 color='blue')\n\nplt.plot(param_range, test_mean, \n         color='green', linestyle='--', \n         marker='s', markersize=5, \n         label='Validation accuracy')\n\nplt.fill_between(param_range, \n                 test_mean + test_std,\n                 test_mean - test_std, \n                 alpha=0.15, color='green')\n\nplt.grid()\nplt.xscale('log')\nplt.legend(loc='lower right')\nplt.xlabel('Parameter n_estimators')\nplt.ylabel('Accuracy')\n# plt.ylim([0.8, 1.0])\nplt.tight_layout()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-09-18T07:33:32.562509Z","iopub.execute_input":"2023-09-18T07:33:32.563577Z","iopub.status.idle":"2023-09-18T07:33:41.568558Z","shell.execute_reply.started":"2023-09-18T07:33:32.563537Z","shell.execute_reply":"2023-09-18T07:33:41.567246Z"},"trusted":true},"execution_count":null,"outputs":[]}]}